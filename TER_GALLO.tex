\documentclass[12pt]{article}
\author{Mathieu GALLO}
\title{Travaux d'étude et de recherche}
\setlength{\hoffset}{-70pt}
\setlength{\textwidth}{481pt}
\setlength{\topmargin}{0pt}
\setlength{\headheight}{0pt}
\setlength{\headsep}{0pt}
\renewcommand{\baselinestretch}{1.4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{fourier}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{color}
\usepackage{pgfornament}
\usepackage[french]{babel}
\usepackage{aliascnt}
\usepackage{cleveref}
\usepackage{subcaption,graphicx}
\usepackage{wrapfig}
\usepackage[toc,page]{appendix}
\usepackage{framed}
\usepackage[A4]{vmargin}
\setmarginsrb{2cm}{1.2cm}{2cm}{1.5cm}{0.5cm}{0.5cm}{0cm}{1cm} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% THEOREMES STYLE %%%%%%%%%%%%
\theoremstyle{definition}
\newtheorem*{notation}{Notation}
\newtheorem*{definition}{Défintion}
\newtheorem*{fait}{Fait}
\newtheorem*{defft}{Définition \& Théorème}
\newtheorem{theoreme}{Théorème}
\crefformat{theoreme}{\textbf{théorème #1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newcommand{\boxXx}[1]{\noindent\fbox{\begin{minipage}[t]{\textwidth}\vspace{2pt}#1\vspace{2pt}\end{minipage}}\medskip}

\newcommand{\titleBar}{\hspace{0.6em}\titlerule}

\newcommand{\sev}{\underset{\text{s.e.v}}{\subset}}

\renewenvironment{leftbar}{%
	\def\FrameCommand{\vrule width 0.4pt \hspace{10pt}}%
	\MakeFramed {\advance\hsize-\width \FrameRestore}}%
{\endMakeFramed}
\renewcommand{\appendixtocname}{Annexes}
\renewcommand{\appendixpagename}{Annexes} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\titleformat{name=\section,numberless}  
{\normalfont\large\bfseries}% format
{}% label
{0pt}% sep
{\MakeUppercase}
[\titlerule]
\titleformat{name=\section}  
{\normalfont\large\bfseries}% format
{}% label
{0pt}% sep
{\thesection~\MakeUppercase}
[\titlerule]

\titleformat{\subsection}  
{\normalfont\normalsize\bfseries}% format
{}
{0pt}% sep
{ \arabic{section}.\arabic{subsection}.~ \MakeUppercase}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[backend=bibtex,style=ieee,dashed=false]{biblatex}
\addbibresource{bibliographie.bib}


\begin{document}

\begin{titlepage}
	\begin{center}
		
		\textsc{\LARGE Sorbonne Université}\\[2cm]
		
		\textsc{\Large Travaux d'étude et de recherche}\\[1.5cm]
		

		\HRule \\[0.4cm]
		{ \huge \bfseries Autour du théorème de Dvoretzky\\[0.4cm] }
		

		\HRule \\[2cm]
		
		\vspace{1cm}
		\begin{center}
			\textit{"It soon became clear that an outstanding breakthrough in Geometric Functional Analysis had been achieved."}  \\
			\footnotesize Vitali Milman à propos du théorème de Dvoretzky dans \textit{Dvoretzky theorem - thirty years later}
		\end{center}

		
		\vfill 
		
		\begin{minipage}{0.4\textwidth}
			\begin{flushleft} 
				Mathieu GALLO \\
			\end{flushleft}
		\end{minipage}
		\begin{minipage}{0.4\textwidth}
			\begin{flushright} 
				\emph{Enseignant :} Omer Friedland\\
			\end{flushright}
		\end{minipage}
		
		\vspace{5mm}		
		{ date}
		
	\end{center}
\end{titlepage}

\tableofcontents\newpage
\section*{Introduction}\addcontentsline{toc}{section}{Introduction}
\markboth{Introduction}{}
Le mémoire suivant suit la série de lectures de Gideon Schetchman , "\textit{Euclidean sections of convex bodies}" \cite{GS1}.\par
Alexandre Grothendieck en 1956 dans son article "\textit{Sur certaines classes de suites dans les espaces de Banach et le théorème de Dvoretzky-Rogers}" \cite{AG}, inspiré par le lemme de Dvoretzky-Rogers (1950) propose une conjecture à laquelle Aryeh Dvoretzky répondra positivement en 1961, aboutissant au résultat suivant :
\newline\boxXx{
	\begin{theoreme}[A. Dvoretzky, 1961]\label{Dvo}
		Il existe une fonction $k:]0,1[\times \mathbb{N}\to \mathbb{N}$, tel que $\forall \varepsilon\in]0,1[$, $k(\varepsilon,n)\stackrel{n\to\infty}{\longrightarrow}\infty$ et pour tout $n\in\mathbb{N}$ et tout compact convexe symétrique $K\subset \mathbb{R}^n$, il existe $V \sev \mathbb{R}^n$ tels que :
		\begin{enumerate}
			\item[(i)] $\dim V =k(\varepsilon,n)$
			\item[(ii)] $\exists r>0$ tel que , $\; r.(V\cap B^n_2) \subset V\cap K \subset (1+\varepsilon)r.(V\cap B^n_2) $
		\end{enumerate}
	\end{theoreme}
}
Dans le papier original de Dvortezky l'estimation de $k$ était :
\begin{equation*}
k(\varepsilon,n)\geq c(\varepsilon)\sqrt{\frac{\log n}{\log \log n}} \hspace{1cm} \text{pour un $c(\varepsilon)>0$}
\end{equation*} 
Vitali Milman en 1971 donna une nouvelle preuve du théorème de Dvoretzky en utilisant le phénomène de concentration de la mesure \cite{VM1}, il a de plus amélioré le théorème en donnant l'estimation de la dépendance en $n$ pour la dimension de $V$:  $k(\varepsilon,n)\geq c(\varepsilon).\log(n)$.
\newline\boxXx{
	\begin{theoreme}[V. Milman, 1971]\label{thmMil}
		Pour tout $\varepsilon>0$, il existe une constante $c>0$ tel que pour tout $n\in\mathbb{N}$ et pour tout compact convexe symétrique $K\subset \mathbb{R}^n$, il existe  $V\sev  \mathbb{R}^n$ tels que :
		\begin{enumerate}
			\item[(i)] $\dim V \geq c.\log(n)$
			\item[(ii)] $\exists r>0$ tel que , $\; r.(V\cap B^n_2) \subset V\cap K \subset (1+\varepsilon)r.(V\cap B^n_2) $
		\end{enumerate}
	\end{theoreme}
}
La dépendance de $c$ par rapport à $\varepsilon$ donné par V.Milman était $c \sim \frac{\varepsilon^2}{\log{\frac{1}{\varepsilon}}}$ \cite{VM1}, c'est cette dépendance qui serras démontrée dans ce mémoire. Y.Gordon à montrer en 1988 l'on pouvais prendre $c\sim \varepsilon^2$ avec les même outils que V.Milman dans \cite{YG}, plus récemment en 2006, G.Schechtman à montrer que l'on pouvais prouver le théorème de Dovretzky avec la même preuve que V. Milman pour $c\sim \varepsilon^2$  en construisant de manière plus précise le $\theta$-net \cite{GS2} (voir preuve de \textbf{théorème \ref{mtool}}) .
\newpage\begin{notation}
	Pour la suite on utiliseras les notations : 
	\begin{enumerate}
		\item[-] $|.|_n$ la norme euclidienne sur $\mathbb{R}^n$, ou $|.|$ si il n'y a pas d'ambiguïté sur la dimension.
		\item[-] $S^{n-1} = \big\{x\in \mathbb{R}^n\; ;\; |x|=1\big\}$, la $(n-1)$-sphère euclidienne. 
	\end{enumerate}
\end{notation}

\begin{wrapfigure}{r}{0.33\textwidth}
	\centering
	%\vspace{-3mm}
	\includegraphics[scale=0.4]{figure_1.png}
\end{wrapfigure}

\noindent Commençons par donner une légère interprétation géométrique du théorème, prenons l'exemple de $K = B_{||.||_\infty}$ dans le cas $n=2$ la distance entre un point situé sur un quart du cercle et le coin le plus proche est $\sqrt{2}-1$, nous pouvons facilement généraliser cela pour $n>2$. Prenons par exemple les points $A =(\frac{1}{\sqrt{n}},...,\frac{1}{\sqrt{n}})\in S^{n-1}$ et $B = (1,...,1)\in \partial B_\infty^n$ le coin de $B_\infty^n$ le plus proche de $A$, on peut joindre $A$ aux points $e_j\in \partial B_\infty^n\cap S^{n-1}$ de la base canonique pour $1\leq j\leq n$, et on a les distances suivantes :
\begin{align*}
|A-e_j|=& \sqrt{2(1-\frac{1}{\sqrt{n}})} \underset{n\to\infty}{\to} \sqrt{2} \\
|e_i-e_j|=& \sqrt{2} \text{\hspace{2mm} pour $i\neq j$}\\
|A-B|=& \sqrt{n}-1 \underset{n\to\infty}{\to} \infty\\
|e_j-B|=& \sqrt{n-1} \underset{n\to\infty}{\to} \infty
\end{align*}
Donc lorsque $n$ est grand, si l'on se place sur la $(n-1)$-sphère euclidienne, $B_\infty^n$ semble être formé de $2^n$ \textit{"piques"} qui sont de plus en plus grands avec $n$. Mais le théorème de Dvoretzky nous affirme qu'il existe une section $C$ de $B_\infty^n$ de dimension supérieure à $c\log n$ où $c$ ne dépendant \par
\begin{wrapfigure}{l}{0.33\textwidth}
	\centering
	\vspace{-7mm}
	\includegraphics[scale=0.4]{figure_2.png}
\end{wrapfigure}
\noindent pas de $n$, tel que $C$ soit arbitrairement proche de la boule euclidienne, c'est-à-dire une section sur laquelle on ne voit pas ces \textit{"piques"}. En terme plus mathématique, pour tout $\varepsilon>0$ il existe $V \sev \mathbb{R}^n$ de dimension plus grande que $c(\varepsilon)\log n$ tel que pour un certain $r>0$ :
\begin{equation*}
r.(V\cap B^n_2) \subset V\cap B_\infty^n \subset (1+\varepsilon)r.(V\cap B^n_2)
\end{equation*}
Nous allons maintenant donner une reformulation du théorème de Dvoretzky en terme de norme, en utilisant la relation entre un compact convexe symétrique $K$ et la norme $||y||_K=\inf\big\{\lambda \;  ; \; \frac{y}{\lambda}\in K \big\}$.
\newline\boxXx{
\begin{definition}
	Soit $(X,||.||_X),(Y,||.||_Y)$ deux espaces normés et $C> 0$, on dit que $X$ s'injecte $C$-continûment dans $Y$, si il existe $T\in\mathcal{L}(X,Y)$ tel que pour tout $x\in X$
	\begin{equation*}
		||x||_X\leq ||Tx||_Y\leq C||x||_X
	\end{equation*}  
\end{definition}
}

\boxXx{
	\begin{theoreme}\label{thmr}
	Pour tout $\varepsilon>0$ il existe $c>0$ tel que pour tout $n\in \mathbb{N}$ et pour toute normes $||.||$ sur $\mathbb{R}^n$ ,  $\ell^k_2$ s'injecte $(1+\varepsilon)$-continûment dans $(\mathbb{R}^n,||.||)$ pour un $k\geq c.\log(n)$. 
	\end{theoreme}
}

\noindent Montrons que le \cref{thmMil} et le \cref{thmr} sont équivalents.

\noindent(2)$\Rightarrow$(3)\\
Posons $K=\text{Adh}(B_{||.||}(0,1))=\{x\in\mathbb{R}^n \; | \; ||x||\leq 1 \}$ et appliquons le théorème 2, celui-ci nous procure un sous-espace $V$ de $\mathbb{R}^n$, avec $\dim V := k \geq c.\log(n)$ et $V\cap K$ est $\varepsilon\text{-ecuclidien}$. Donnons-nous une base orthonormée $\{v_j\}_{1\leq j \leq k}$ de $V$ et posons 
\begin{equation*}
T :\begin{array}{ccc}
 (\mathbb{R}^k,|.|_k)& \mapsto &(V,||.||) \\
\sum_{i=1}^{k}x_i e_i & \to & \sum_{i=1}^{k}x_i v_i
\end{array}
\end{equation*}
Soit $x\in \mathbb{R}^k$ tel que $||Tx||=1$, comme $K\cap V$ est $\varepsilon$-euclidien on a que 
\begin{equation*}
r \leq |Tx|_n \leq (1+\varepsilon)r, \hspace{2mm}\text{pour un $r>0$}
\end{equation*}
La borne supérieure est immédiate car  $K\cap V \subset r(1+\varepsilon).(V\cap B^n_2)$, pour la borne inférieure il suffit de remarquer que $(V\cap K)$ est un fermer de $V$ qui contient l'ouvert $r.(V\cap B^n_2)$ de $V$, comme $Tx$ est dans la frontière de $K\cap V$ il n'est pas dans l'intérieur de $K\cap V$ et donc dans aucun ouvert contenu dans $V\cap K$. Remarquons que $|Tx|_n=|x|_k$, donc
\begin{equation*}
	r \leq |x|_k \leq (1+\varepsilon)r
\end{equation*}
Il suffit d'appliqué cela à $\frac{x}{||Tx||}$ pour $x\neq 0$ 
\begin{equation*}
	r||Tx|| \leq |x|_k \leq (1+\varepsilon)r||Tx||
\end{equation*}
\begin{equation*}
	\frac{1}{(1+\varepsilon)r}|x|_k \leq ||Tx|| \leq \frac{1}{r} |x|_k
\end{equation*}
\begin{equation*}
r|x|_k \leq ||\tilde{T}x|| \leq (1+\varepsilon)r|x|_k
\end{equation*}
avec $\tilde{T} = r(1+\varepsilon)T$, remarquons que la quantité importante est $||T||.||T^{-1}||=||\tilde{T}||.||\tilde{T}^{-1}||\leq 1+\varepsilon$.\\ 
(3)$\Rightarrow$(2)\\
Soit $\varepsilon>0$ , par le théorème 3 il existe $c>0$ tel que pour tous $n\in\mathbb{N}$ il existe un $k>c.\log(n)$ et $\ell_2^k$ s'injecte ($1+\varepsilon$)-continûment dans ($R^n,||.||$) pour n’importe quelle norme $||.||$ sur $\mathbb{R}^n$. Considérons un compact convexe symétrique $K\subset \mathbb{R}^n$ et $||y||=\inf\Big\{\lambda>0\; ;\; \frac{y}{\lambda}\in K\Big\}$, alors $\exists T :\ell^{k}_2\to(\mathbb{R}^n,||.||)$ linéaire tel que :
\begin{equation*}
\forall x \in \mathbb{R}^k \; , \;\; |x|\leq ||Tx||\leq (1+\varepsilon)|x|
\end{equation*}
ceci implique immédiatement que $T$ est injective, notons $V=\text{Im}T$, alors la co-restriction à $V$ de $T$ est bijective.
Soit $y\in \partial(K\cap V)$, c'est-à-dire $||y||=1$, on sait qu'il existe un unique $x\in\mathbb{R}^k$ tel que $Tx=y$, on en déduit donc 
\begin{equation*}
|x|\leq 1 \leq (1+\varepsilon)|x|\; \iff\; \frac{1}{1+\varepsilon}\leq|x|\leq 1
\end{equation*}
la convexité et la symétrie centrale de $K\cap V$ implique :
\begin{equation*}
	\frac{1}{1+\varepsilon}T(B_2^k)\subset K\cap V \subset T(B_2^k)
\end{equation*}
Pour conclure nous nous référençons au \textbf{lemme \labelcref{eleb}} qui seras démontrer par la suite qui dit que toutes ellipsoïdes de dimension $k$ admet une section de dimension $[k/2]$ qui soit un multiple d'une boule euclidienne. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\numberwithin{theoreme}{section}
\newaliascnt{lemme}{theoreme}
\newtheorem{lemme}[lemme]{Lemme}
\aliascntresetthe{lemme}
\crefname{lemme}{lemme}{lemmes}
\crefformat{lemme}{\textbf{lemme #1}}

\newaliascnt{rem}{theoreme}
\newtheorem{rem}[rem]{Remarque}
\aliascntresetthe{rem}
\crefname{rem}{remarque}{remarques}
\crefformat{rem}{\textbf{remarque #1}}

\newaliascnt{proposition}{theoreme}
\newtheorem{proposition}[proposition]{Proposition}
\aliascntresetthe{proposition}
\crefname{proposition}{proposition}{proposition}
\crefformat{proposition}{\textbf{proposition #1}}

\newaliascnt{cor}{theoreme}
\newtheorem{cor}[cor]{Corollaire}
\aliascntresetthe{cor}
\crefname{cor}{corollaire}{corollaires}
\crefformat{cor}{\textbf{corollaire #1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Préliminaire}

\subsection{Mesures de Haar}
La mesure de Haar est une notion introduite par Alfred Haar en 1933, il démontre que dans tous groupe localement compact a base dénombrable il existe une mesure borélienne invariante par translation à gauche, en 1935 John V.Neumann montre que de plus cette mesure est unique à un coefficient multiplicatif près, son application seras étendu après à tous les groupes localement compact, nous ademetrons le théorème suivant (voir \cite{VMGS}).
\newline\boxXx{
	\begin{defft}[Mesures de Haar]
		Soit $(X,d)$ un espace métrique, $G$ un groupe topologique localement compact qui agit sur $X$ et tel que :
		\begin{equation}\tag{$\star$}
		\forall x,y\in X \; \; \forall g \in G  \; , \; d(gx,gy)=d(x,y)
		\end{equation} 
		alors il existe une unique mesure à un coefficient multiplicatif près, régulière définie sur les boréliens de $X$ qui est invariante sous l'action de $G$, cette mesure est appelée mesure de Haar de $X$ (où $G$ est sous-entendu).
	\end{defft}
}
Les 2 exemples suivant d'espace métrique vérifie ($\star$) pour $G=O(n)$,
\begin{enumerate}
	\item[(i)] $X=S^{n-1}$ muni de la distance euclidienne
	\item[(ii)] $X=O(n)$ avec la norme $||T||=\sup_{|x|=1}|Tx|$
\end{enumerate}
\begin{notation}
	Par le théorème précédent on peut définir sans ambiguïté $\mu$ et $\nu$ les mesures de Haar normalisés respectivement sur $S^{n-1}$ et $O(n)$.
\end{notation}
Montrons quelques propriétés qui seront utiles par la suite.
\newline\boxXx{
	\begin{lemme}\label{lhg}
		Soit $f\in C(S^{n-1})$ et $Y=(g_1,...,g_n)$ où les $\{g_i\}_{1\leq i\leq n}$ sont i.i.d suivant une loi normale $\mathcal{N}(0,1)$, alors 
		\begin{equation*}
		\int_{S^{n-1}}fd\mu = \mathbb{E}\Bigg[f\Big(\frac{Y}{|Y|}\Big)\Bigg]
		\end{equation*}
	\end{lemme}
}
\begin{proof}
	Par unicité de la mesure de Haar , il nous suffit de montrer que pour tous $M\in O(n)$ et $f\in C(S^{n-1})$ :
	\begin{equation*}
	\mathbb{E}\Bigg[f\Big(\frac{MY}{|MY|}\Big)\Bigg]=\mathbb{E}\Bigg[f\Big(\frac{Y}{|Y|}\Big)\Bigg]
	\end{equation*}
	\begin{equation*}
	\mathbb{E}\Bigg[f\Big(\frac{MY}{|MY|}\Big)\Bigg] = \int_{\mathbb{R}^n\backslash\{0\}} f\big(\frac{My}{|y|}\big)\exp\Big\{-\frac{1}{2}|y|^2\Big\}dy_1...dy_n=\int_{\mathbb{R}^n\backslash\{0\}} \frac{1}{|\det M|}f\big(\frac{y}{|y|}\big) \exp\Big\{-\frac{1}{2}|M^{-1}y|^2\Big\}dy_1...dy_n
	\end{equation*}
	comme $|\det M|=1$ et $|M^{-1}y|=|y|$, on a : 
	\begin{equation*}
	\mathbb{E}\Bigg[f\Big(\frac{MY}{|MY|}\Big)\Bigg] = \mathbb{E}\Bigg[f\Big(\frac{Y}{|Y|}\Big)\Bigg]
	\end{equation*}
\end{proof}

\boxXx{
	\begin{lemme}\label{lhso}
		Soit $A\subset S^{n-1}$ un borélien alors pour tous $x\in S^{n-1}$  
		\begin{equation*}
			\nu\Big( T\in O(n) \;;\; Tx\in A\Big) = \mu\big(A \big)
		\end{equation*}
	\end{lemme}
}
\begin{proof}
	Soit $M \in O(n)$ et $x\in S^{n-1}$ alors la mesure définie par
	\begin{equation*}
	\omega_x(A)= \nu\Big( T\in O(n) \;;\; Tx\in A\Big)
	\end{equation*}
	$\omega_x$ vérifie les propriétés suivantes :
	\begin{equation*}
	\omega_x(MA)= \nu\Big( T\in O(n) \;;\; M^{T}Tx\in A\Big)=\nu\Big( T\in O(n) \;;\; Tx\in A\Big)=\omega_x(A)
	\end{equation*}
	\begin{equation*}
	\omega_x(\emptyset)=0
	\end{equation*}
	\begin{align*}
	\omega_x\big(\bigsqcup_{i\in \mathbb{N}}A_i\big)&= \nu\Big( T\in O(n) \;;\; Tx\in \bigsqcup_{i\in \mathbb{N}}A_i\Big)=\nu\Big(\bigsqcup_{i\in\mathbb{N}}\big\{T\in O(n) \;;\;  Tx\in A_i \big\}\Big)\\
	& =\sum_{i\in\mathbb{N}}\nu\Big(T\in O(n) \;;\;  Tx\in A_i \Big)=\sum_{i\in\mathbb{N}}\omega_x(A_i)
	\end{align*}
	L'unicité de la mesure de Haar nous permet de conclure que $\omega_x  = \mu$, en particulier $\omega_x$ ne dépend pas de $x$.
\end{proof}
\subsection{Concentration de la mesure}
Le phénomène de concentration de la mesure a été mis en avant par V.Milman étandant les travaux de P.Lévy et son inégalité isopérimétrique. On peut formuler la question que cherche à résoudre le théorème comme cela : étant donné $(X,d)$ un espace métrique muni d'une mesure de probabilité $P$, on cherche à regarder où les fonctions $1$-Lipschitziennes sont essentiellement constantes. Considérons $f$ une fonctions $1$-Lipschitzienne de $X$ dans $\mathbb{R}$ et notons $m_f$ sa médiane, c'est a dire le réel tel que \begin{equation*}
	P(f\geq m_f)\geq \frac{1}{2} \hspace{5mm} \& \hspace{5mm} P(f\leq m_f)\geq \frac{1}{2}
\end{equation*}
L'assertion $f$ est essentiellement constante se traduit par le faite que l'on puisse donner une borne supérieur à $P\big(|f-m_f|\geq \varepsilon\big)$, pour $\varepsilon\geq 0$ .\\
Posons $A=\big\{ f\leq m_f \big\}$, il est assez naturelle de s'intéresser à l'ensemble suivant 
\begin{equation*}
	A_\varepsilon =\big\{x\in X \; ; \; d(x,A)\leq \varepsilon\big\}
\end{equation*}
On appelle $A_\varepsilon$ le $\varepsilon$-élargissement de $A$, il suit cela : 
\begin{equation*}
	x\in A_\varepsilon \Rightarrow f(x)\leq \varepsilon+m_f\hspace{5mm}\iff\hspace{5mm} A_\varepsilon \subset \Bigg\{x\in S^{n-1} \; ; \; f(x)\leq \varepsilon+m_f\Bigg\}
\end{equation*}
\begin{align*}
	P(f>\varepsilon+m_f)&= 1 - P(f\leq \varepsilon+m_f)\\
	&\leq 1 - P(A_\varepsilon)
\end{align*}
Cette observation a permis a Milman et Gromov de se ramener a une étude ensembliste du problème. Ils introduisent $\alpha$ une fonction dite de concentration, définit comme le plus petit réel tel que:
\begin{equation*}
\forall A\subset X , \; P(A)\geq \frac{1}{2}\hspace{3mm} \Rightarrow\hspace{3mm} 1-P(A_\varepsilon)\leq \alpha(\varepsilon,P)
\end{equation*}
Appliquant ceci au ensemble  $\Big\{f\geq m_f\Big\}$ et $\Big\{f\leq m_f\Big\}$, on trouve facilement :
\begin{equation*}
	P(|f-m_f|>\varepsilon)\leq 2 \alpha(\varepsilon,P)
\end{equation*}
Considérons maintenant que $f$ est $L$-Lipschitzienne, alors la médiane de $\frac{f}{L}$ est $\frac{m_f}{L}$, donc par homogénéité 
\begin{equation*}
	P(|f-m_f|>\varepsilon)\leq 2 \alpha(\frac{\varepsilon}{L},P)
\end{equation*}
L'utilité de cette formulation est que dans certains cas $\alpha$ décroît très vite vers 0 lorsque $\varepsilon$ devient grand. Pour certains espace $X$ il est possible de remplacer la médiane par l'espérance qui est en générale plus simple a calculer, dans le cas ou $X$ est la $(n-1)$-sphère euclidienne on dispose du théorème suivant qui seras admis (voir \cite{GS3} ou \cite{VMGS}) .
\newline\boxXx{
	\begin{theoreme}[Concentration de la mesure sur la sphère]
		Soit $f:S^{n-1}\to \mathbb{R}$ une fonction Lipschitzienne de constante $L>0$, alors 
		\begin{equation*}
		\mu\Big\{x\in S^{n-1}\; ; \; |f(x)-\mathbb{E}[f]|>\varepsilon\Big\}\leq 2e^{-\frac{\varepsilon^2n}{2L^2}}
		\end{equation*}
		Où $\mathbb{E}[f]=:\int_{S^{n-1}}fd\mu$
	\end{theoreme}
}
\subsection{Ellipsoïdes}
Dans cette partie nous montrons plusieurs propriétés sur les ellipsoïdes, commençons par les définir :
\newline\boxXx{
	\begin{definition}
		On appelle ellipsoïde de $\mathbb{R}^n$ l'image de la boule unité euclidienne par un élément de $GL(n)$. 
	\end{definition}
}
\noindent Donnons une définition alternative d'un l'ellipsoïde.
\newline\boxXx{
	\begin{proposition}
		Pour toute ellipsoïde $\mathcal{E}$ il existe $\alpha_1,...,\alpha_n>0$ et $v_1,...,v_n$ une base orthonormé tel que :
		\begin{equation*}
		\mathcal{E}=\big\{x\in\mathbb{R}^n\; \; ; \; \sum_{i=1}^{n}\frac{<x,v_i>^2}{\alpha_i^2}< 1\big\}
		\end{equation*}
	\end{proposition}
}
\begin{proof}
	Donnons nous $A\in GL(n)$ tel que $AB_2^n=\mathcal{E}$
	\begin{equation*}
	|Ax|^2 = x^T A^TAx 
	\end{equation*}
	$A^T A$ est symétrique, soit $\lambda$ une de ses valeur propre et $v$ un vecteur propre associé, alors  
	\begin{equation*}
	0< |Av|^2 = v^T \lambda v = \lambda |v|^2
	\end{equation*}
	Donc les valeurs propre $A^TA$ sont strictement positive, Comme elle est symétrique, elle est donc diagonalisable dans une base orthonormé, donnons nous $(\lambda_i)_{i\leq n}$ et $(v_i)_{i\leq n}$ une base orthonormé tel que $A^TAv_i = \lambda_i^2 v_i$ pour tous $1\leq i\leq n$ et définissons les quantités suivante :
	\begin{enumerate}
		\item[-] $P$ la matrice définie par $Pv_j = \lambda_j v_j$
		\item[-] $u_j=\lambda_j^{-1}Av_j$
	\end{enumerate}
	Montrons que les $u_j$ forment une base orthonormée: 
	\begin{align*}
	<u_i,u_j> &= \lambda_j^{-1}v_j^TA^T \lambda_i^{-1}Av_i\\
	&=\lambda_j^{-1}\lambda_i^{-1}v_j^T(A^T Av_i) \\
	&= \lambda_j^{-1}\lambda_i^{-1}v_j^T \lambda_i^2 v_i\\
	&=\frac{\lambda_i}{\lambda_j} <v_j,v_i> = \left\{ \begin{array}{ll} 0 \hspace{1mm}\text{si $i\neq j$} \\ 1 \hspace{1mm}\text{sinon} \end{array} \right.
	\end{align*}
	Soit $x = \sum_{i=1}^{n}x_i v_i\in S^{n-1}$  
	\begin{align*}
	y=: Ax&= x_1Av_1+...+x_nAv_n \\ 
	&= x_1 \lambda_1 u_1 + ... + x_n \lambda_n u_n
	\end{align*}
	Les composante de $y$ dans la base $\{u_j\}_{j\leq n}$ sont $<y,u_j> = x_j\lambda_j$, donc :
	\begin{equation*}
	\frac{<y,u_1>^2}{\lambda_1^2}+...+\frac{<y,u_n>^2}{\lambda_n^2} = x_1^2+...+x_n^2 =1
	\end{equation*}
	Et finalement $\partial \mathcal{E} = \big\{y\in\mathbb{R}^n \; ; \; \frac{<y,u_1>^2}{\lambda_1^2}+...+\frac{<y,u_n>^2}{\lambda_n^2} = 1\big\} $.
\end{proof}

\noindent Démontrons maintenant le lemme que nous avons utiliser dans l'introduction :
\newline\boxXx{
	\begin{lemme}\label{eleb}
		Soit $\mathcal{E}$ un ellipsoïde de $\mathbb{R}^n$, alors $\exists \lambda >0$ et $V\sev\mathbb{R}^n$ de dimension $\big\lceil\frac{n}{2}\big\rceil$ tel que :
		\begin{equation*}
		\mathcal{E}\cap V = \lambda B^n_2\cap V
		\end{equation*}
\end{lemme}}
\begin{proof}
	Quitte a effectuer une rotation on peut supposer que $\mathcal{E} = \big\{x\in\mathbb{R}^n \hspace{1mm}; \hspace{1mm} \sum_{i=1}^{n}a_i x_i^2< 1 \big\}$ pour $0\leq a_1 \leq ... \leq a_n$. Posons $\lambda = \text{Mediane}(a_1,...,a_n)$ et 
	\begin{equation*}
	F = \big\{x\in\mathbb{R}^n \hspace{1mm};\hspace{1mm} \forall i\leq \big\lfloor\frac{n}{2}\big\rfloor , \; \sqrt{\lambda-a_i}x_i=\sqrt{a_{n+1-i}-\lambda}x_{n+1-i}\big\}
	\end{equation*}
	Alors pour tous $x\in F$ nous avons $\forall i\leq \big\lfloor\frac{n}{2}\big\rfloor$:
	\begin{equation*}
	a_ix_i^2+a_{n+1-i}x_{n+1-i}^2 = \lambda (x_i^2+x_{n+1-i}^2)
	\end{equation*}
	d'où
	\begin{equation*}
	\sum_{i=1}^{n}a_ix_i^2 = \lambda \sum_{i=1}^{n}x_i^2 
	\end{equation*}
\end{proof}
Nous admettons le résultat de F.John : 
\newline\boxXx{
	\begin{defft}[Ellipsoïde de John]
		Tous compact convexe symétrique d'intérieur non vide contient un unique ellipsoïde de volume maximale, elle est appelée ellipsoïde de John.
	\end{defft}
}
\begin{leftbar}
\begin{rem}\label{rem0}
Soit $K\subset \mathbb{R}^n$ un compact convexe symétrique et $D=u(B_2^n)$ (avec $u\in GL(n)$) son ellipsoïde de John, notons alors $C=:u^{-1}(K)$ dont l'ellipsoïde de John est $B_2^n$, supposons que
\begin{equation*}
r (B_2^n\cap W)\subset C\cap W \subset r(1+\varepsilon)(B_2^n\cap W)
\end{equation*}
alors 
\begin{equation*}
u^{-1}\big(r(D\cap uW)\big)\subset u^{-1}(K\cap uW)\subset u^{-1}\big(r(1+\varepsilon)(D\cap uW)\big)
\end{equation*}
\begin{equation*}
r(D\cap uW)\subset K\cap uW \subset r(1+\varepsilon)(D\cap uW)
\end{equation*}
Le \cref{eleb} nous permet de conclure que quitte à diviser la dimension du sous-espace $W$ par deux, on peut se restreindre à montrer le théorème de Dvoretzky pour des compacts dont la boule euclidienne est l'ellipsoïde de John sans perte de généralité.
\end{rem}\end{leftbar}
\subsection{Loi gaussienne}
Pour la preuve du théorème de Dvoretzky nous aurons besoins de deux résultat sur les variables aléatoires gaussiennes, ce premier combiner avec \cref{lhso} nous seras utile pour calculer des intégrales par rapport à la mesure de Haar sur la $(n-1)$-sphère.
\newline\boxXx{
	\begin{lemme}\label{gaussind}
		Soit $g=(g_1,...,g_n)$ des variables aléatoire i.i.d suivant une loi gaussienne, alors 	$\frac{g}{|g|}$ et $|g|$ sont indépendants.
	\end{lemme}
}
\begin{proof}
	Posons $Y =\frac{g}{|g|}$ et $R = |g|$ alors
	\begin{equation*}
	\mathbb{E}\big[f(Y)g(R)\big]=\int_{\mathbb{R}^{n}}f\big(\frac{x_1}{|x|},...,\frac{x_n}{|x|}\big)g(|x|) \exp\Big(-\frac{|x|^2}{2}\Big) dx_1...dx_n
	\end{equation*}
	en passant en coordonnées sphériques
	\begin{align*}
	x_1 = & r\sin \theta_1 ... \sin \theta_{n-1}\\
	x_2 = & r\sin \theta_1 ...\sin \theta_{n-2}\cos \theta_{n-1}\\
	x_3 = & r\sin \theta_1 ...\sin \theta_{n-3}\cos \theta_{n-2}\\
	\vdots\\
	x_n = & r \cos \theta_1
	\end{align*}
	On a le déterminant suivant : 
	\begin{equation*}
	dx_1 ... dx_n = r^{n-1}\prod_{1\leq i\leq n-1}(\sin\theta_i)^{n-1-i} dr d\theta_1 ... d\theta_{n-1}
	\end{equation*}
	d'où :
	\begin{equation*}
	\mathbb{E}\big[f(Y)g(R)\big]=\int_{\mathbb{R}^{n}}f\circ\varphi(\theta)g(r) \exp\Big(-\frac{r^2}{2}\Big)r^{n-1}\prod_{1\leq i\leq n-1}(\sin\theta_i)^{n-1-i}dr d\theta_1 ... d\theta_{n-1}
	\end{equation*}
	\begin{equation*}
		\mathbb{E}\big[f(Y)g(R)\big]=\int_{\mathbb{R}}g(r) \exp\Big(-\frac{r^2}{2}\Big) r^{n-1}dr\int_{\mathbb{R}^{n-1}} f\circ\varphi(\theta)\prod_{1\leq i\leq n-1}(\sin\theta_i)^{n-1-i}d\theta_1 ... d\theta_{n-1}
	\end{equation*}
	où $\varphi(\theta)=(\sin \theta_1 ... \sin \theta_{n-1},\sin \theta_1 ...\sin \theta_{n-2}\cos \theta_{n-1},\sin \theta_1 ...\sin \theta_{n-3}\cos \theta_{n-2},\dots,\cos \theta_1)$.
\end{proof} 
Nous aurons besoins de trouver un minorant pour $\int_{S^{n-1}}||x|| d\mu(x)$ pour une norme $||.||$ sur $\mathbb{R}^n$ et pour cela nous aurons besoin du lemme suivant :
\newline\boxXx{
	\begin{lemme}\label{ming}
		il existe $c>0$ tel que $\forall N>1$ et $\{g_i\}_{1\leq i \leq N}$ des variables aléatoire i.i.d suivant une loi $\mathcal{N}(0,1)$ on ait :
		\begin{equation*}
		c \sqrt{\log N} \leq \mathbb{E}\big[\max_{1 \leq i\leq \tilde{N}}|g_i|\big]
		\end{equation*}
		où $\tilde{N} = \Bigg\lceil\frac{N}{2}\Bigg\rceil$ est la partie entière supérieure de $\frac{N}{2}$.
	\end{lemme}
}
\begin{proof}
	Commençons par montrer que pour $n>1$, $\mathbb{P}\big(|g_1|> \sqrt{\log n}\big) \geq \frac{1}{n}$, on a :
	\begin{equation*}
	\mathbb{P}\big(|g_1|> \sqrt{\log n}\big) = 2 \int_{\sqrt{\log n}}^{+\infty}e^{-\frac{x^2}{2}}dx\geq \int_{\sqrt{\log n}}^{+\infty}e^{-\frac{x^2}{2}}(1+\frac{1}{x^2})dx  \qquad \text{ pour $x>\sqrt{\log(2)}$}
	\end{equation*}
	\begin{equation*}
	\int_{\sqrt{\log n}}^{+\infty}e^{-\frac{x^2}{2}}(1+\frac{1}{x^2})dx = \Big[-\frac{ e^{-\frac{t^2}{2}}}{t}\Big]_{\sqrt{\log n}}^{+\infty}=\frac{1}{\sqrt{n\log n}}>\frac{1}{n}
	\end{equation*}
	Donc 
	\begin{equation*}
	\mathbb{P}\Big(\max_{1 \leq i\leq \tilde{N}}|g_i|\leq \sqrt{\log N}\Big) = \mathbb{P}\Big(|g_1|\leq \sqrt{\log N}\Big)^{\tilde{N}}=\Bigg(1-\mathbb{P}\Big(|g_1|> \sqrt{\log N}\Big)\Bigg)^{\tilde{N}}
	\end{equation*}
	\begin{equation*}
	\mathbb{P}\Big(\max_{1 \leq i\leq \tilde{N}}|g_i|\leq \sqrt{\log N}\Big)\leq \Bigg(1-\frac{1}{N}\Bigg)^{\tilde{N}}\leq e^{-\frac{\tilde{N}}{N}} \leq e^{-\frac{1}{2}}
	\end{equation*}
	Ce qui équivaut a 
	\begin{equation*}
	\mathbb{P}\Big(\max_{1 \leq i\leq \tilde{N}}|g_i|>\sqrt{\log N}\Big)\geq 1- e^{-\frac{1}{2}}
	\end{equation*}
	Par l'inégalité de Markov on a finalement :
	\begin{equation*}
	\mathbb{E}\big[\max_{1 \leq i\leq \tilde{N}}|g_i|\big]\geq \mathbb{P}\Big(\max_{1 \leq i\leq \tilde{N}}|g_i|> \sqrt{\log N}\Big) \sqrt{\log N}\geq (1-e^{-\frac{1}{2}})\sqrt{\log N}
	\end{equation*}
	avec $c =: 1-e^{-\frac{1}{2}}$ 
\end{proof}

\section{Démonstration du théorème de Dvoretzky}
\subsection{Lemmes d'approximations}
Avant de débuter la démonstration du théorème de Dvoretzky, nous allons avoir besoins de plusieurs lemmes, et de la définition suivante :
\newline\boxXx{
	\begin{definition}
		Soit $(X,d)$ un espace métrique et $\theta>0$, on dit que $A\subset X$ est un $\theta$-net si \begin{enumerate}
			\item[(i)] $A$ est de cardinal fini.
			\item[(ii)] $\forall x \in X$ , $\exists y\in A$ tel que $d(x,y)\leq\theta$ 
		\end{enumerate}
	\end{definition}
}
Le petit lemme qui suit nous permet d'approcher les points de la $(n-1)$-sphère par des points tous situé sur un $\theta$-net.
\newline\boxXx{
	\begin{lemme}\label{lap}
		Soient $x\in S^{n-1}$ , A un $\theta$-net pour un $1>\theta>0$, alors il existe $(y_i)_{i\in\mathbb{N}}\subset A$ et $(\beta_i)_{i\in\mathbb{N}}\subset \mathbb{R}^{+}$ tel que 
		\begin{equation*}
		x = \sum_{i=0}^{+\infty}y_i \beta_i \text{\hspace{4mm} et \hspace{4mm} $\forall i\in \mathbb{N}$, }\; \beta_i\leq \theta^i
		\end{equation*}
	\end{lemme}
}
\begin{proof}
	Comme $A$ est un $\theta$-net alors il existe $y_0\in A$ tel que $|x-y_0|<\theta$, et donc
	\begin{equation*}
	x = y_0 + \lambda_1 x'
	\end{equation*}
	avec $\lambda_1= |x-y_0|\leq \theta$ et $x' = \frac{x-y_0}{\lambda_1}\in S^{n-1}$, on peut donc itéré le même procédé sur $x'$ et réitéré indéfiniment : 
	\begin{equation*}
	\begin{array}{ccc}
	x = y_0 + \lambda_1 (y_1+\lambda_2x'')=y_0+\lambda_1y_1+\lambda_1\lambda_2x'' &\text{\hspace{4mm} avec \hspace{2mm}}&  \lambda_2\leq \theta, \; y_1\in A \text{\hspace{2mm}et\hspace{2mm}} x''\in S^{n-1}\\
	\vdots&\vdots&\vdots\\
	x = y_0 + \sum_{i=1}^{N}y_i\Big(\prod_{1\leq k\leq i}\lambda_k\Big)+\tilde{x}\prod_{1\leq k\leq N+1}\lambda_k &\text{\hspace{4mm} avec \hspace{2mm}}&  \text{$\forall i\leq N+1$\hspace{1mm}} \lambda_i\leq \theta, y_i\in A \text{\hspace{2mm}et\hspace{2mm}} \tilde{x}\in S^{n-1}\\
	\vdots & \vdots & \vdots
	\end{array}
	\end{equation*} 
	Si l'on pose $S_N = y_0 + \sum_{i=1}^{N}y_i\Big(\prod_{1\leq k\leq i}\lambda_k\Big)$, alors :
	\begin{equation*}
	|x-S_N| \leq |\lambda_1 ... \lambda_N| |\tilde{x}|\leq \theta^{N} \to 0  \text{\hspace{3mm}avec\hspace{2mm}}  N\to \infty
	\end{equation*}
	il ne reste plus qu'as poser $\beta_0=1$ et pour $i>0$, $\beta_i=\prod_{1 \leq k\leq i}\lambda_k\leq \theta^i$ et l'on a :
	\begin{equation*}
	x = \sum_{i=0}^{+\infty} \beta_i y_i
	\end{equation*}
\end{proof}
Le \textbf{lemme \ref{lsB}} va nous permettre de passer d'un ensemble de grande $\mu$-mesure a un grand sous-espace au sens des dimensions. 
\newline\boxXx{
	\begin{lemme}\label{lsB}
		$\forall \varepsilon >0$ , il existe $1>\theta>0$ tel que pour tous $n\in \mathbb{N}$ , si l'on a $A$ un $\theta$-net sur $V\cap S^{n-1}$ pour $V\underset{\text{sev}}{\subset}\mathbb{R}^n$ de dimension $k$, $||.||$ une norme sur $\mathbb{R}^{n}$ et $T\in GL(n)$, tel que:
		\begin{equation*}
		\forall  x \in A, \hspace{5mm} (1-\theta)\leq \big|\big|Tx \big|\big|\leq (1+\theta)
		\end{equation*}
		alors ,
		\begin{equation*}
		\forall  x \in V, \hspace{5mm} \frac{1}{\sqrt{1+\varepsilon}}|x|\leq \big|\big|Tx\big|\big|\leq \sqrt{1+\varepsilon}|x|
		\end{equation*}
		de plus si $\varepsilon\leq \frac{1}{9}$, on peu prendre $\theta=\frac{\varepsilon}{9}$
	\end{lemme}
}
\begin{proof} 
	Soient $1>\theta>0$, $A$ un $\theta$-net sur $S(V)=\big\{x\in V \; ;^|x|=1\big\}$ et $x\in S(V)$ par le \cref{lap},  il existe $(y_i)_{i\in\mathbb{N}}\subset A$ et $(\beta_i)_{i\in\mathbb{N}}\subset \mathbb{R}^{+}$ tel que 
	\begin{equation*}
	x = \sum_{i=0}^{+\infty}y_i \beta_i \text{\hspace{4mm} et \hspace{4mm} $\forall i\in \mathbb{N}$, }\; \beta_i\leq \theta^i
	\end{equation*}
	Notons $T=(a_1,...,a_n)$
	\begin{align*}
	||Tx|| &= \big|\big| T\sum_{i=0}^{+\infty}y_i \beta_i\big|\big|\\
	&=  \big|\big| \sum_{i=0}^{+\infty}\beta_i \sum_{p=1}^{n}y_{i,p}a_p \big|\big|\\
	&\leq \sum_{i=0}^{+\infty}\theta^i ||\sum_{p=1}^{n}y_{i,p}a_p||\\
	&\leq \sum_{i=0}^{+\infty}\theta^i ||Ty_i||\\
	& \leq  \sum_{i=0}^{+\infty}\theta^i (1+\theta)=\frac{1+\theta}{1-\theta}
	\end{align*}
	de même :
	\begin{align*}
	||Tx|| &\geq||Ty_0||- ||Tx-Ty_0||\\
	&= (1-\theta) - ||\sum_{p=1}^{n}a_p\sum_{i=1}^{+\infty}\beta_i y_{i,p}||\\
	&\geq (1-\theta)- \sum_{i=1}^{+\infty}\theta^i ||Ty_i||\\
	&\geq \big((1-\theta)- \theta\frac{1+\theta}{1-\theta}\big)=  \frac{1-3\theta}{1-\theta}
	\end{align*}
	Il suffit donc de prendre $\theta$ tel que
	\begin{equation*}
	\begin{array}{cc}
	\sqrt{1+\varepsilon}\geq \frac{1+\theta}{1-\theta}\\
	\frac{1}{\sqrt{1+\varepsilon}}\leq \frac{1-3\theta}{1-\theta}
	\end{array}
	\end{equation*}
	et pour tous $x\in V \backslash\{0\}$ on a 
	\begin{equation*}
	\begin{array}{cc}
	\frac{1}{\sqrt{1+\varepsilon}}\leq\big|\big|T\frac{x}{|x|}\big|\big|\leq  \sqrt{1+\varepsilon}\\
	\frac{1}{\sqrt{1+\varepsilon}}|x|\leq||Tx||\leq |x|\sqrt{1+\varepsilon}
	\end{array}
	\end{equation*}
	Ce qui fini la première partie de la preuve, dans la suite on suppose $\varepsilon\leq \frac{1}{9}$. On cherche $\theta=:\theta(\varepsilon)\in]0,1[$, tel que $\sqrt{1+\varepsilon}\geq \max\big(\frac{1-\theta}{1-3\theta},\frac{1+\theta}{1-\theta}\big)$, supposons $\theta\leq \frac{1}{3}$ alors
	\begin{equation*}
	\frac{1-\theta}{1-3\theta}-\frac{1+\theta}{1-\theta} = \frac{4\theta^2}{(1-3\theta) (1-\theta)}>0
	\end{equation*}
	Donc $\sqrt{1+\varepsilon}\geq \frac{1-\theta}{1-3\theta}$
	\begin{equation*}
	\begin{array}{ccc}
	1+\varepsilon \geq  \big(\frac{1-\theta}{1-3\theta}\big)^2\\
	(9\varepsilon+8)\theta^2 - 2(3\varepsilon+2)\theta +\varepsilon \geq 0\\
	\end{array}
	\end{equation*}
	les deux racines de ce polynôme sont 0<$\frac{3\varepsilon+2-2\sqrt{1+\varepsilon}}{8+9\varepsilon}<\frac{3\varepsilon+2+2\sqrt{1+\varepsilon}}{8+9\varepsilon}$, on cherche donc un $\theta$ dans $]0,\frac{3\varepsilon+2-2\sqrt{1+\varepsilon}}{8+9\varepsilon}]$. Pour finir 
	\begin{align*}
	\frac{3\varepsilon+2-2\sqrt{1+\varepsilon}}{8+9\varepsilon}&\geq \frac{3\varepsilon+2-2-2\varepsilon}{8+9\varepsilon}=\frac{\varepsilon}{8+9\varepsilon}\\
	&\geq \frac{\varepsilon}{9}
	\end{align*}
	donc pour $\varepsilon\in]0,9^{-1}[$ on peu prendre $\theta(\varepsilon)=\frac{\varepsilon}{9}$.
\end{proof}
\boxXx{
	\begin{lemme}\label{lns}
		Pour tous $0<\theta<1$ , $V\sev\mathbb{R}^n$ de dimension $k>0$, alors il existe un $\theta$-net sur $V\cap S^{n-1}$ de cardinal inférieur à $\big(\frac{3}{\theta}\big)^{k}$.
	\end{lemme}
}
\begin{proof}
	Notons $B_V(x,r)=\big\{y\in V\; \; ; \; \; |x-y|< r\big\}$ la boule de centre $x\in V$ et de rayon $r\geq 0$, soit $N=\{x_i\}_{i=1,...,m}$ un sous-ensemble de $V\cap S^{n-1}$ maximal pour la propriété : $x,y\in N$ , $|x-y|\geq \theta$, c'est-à-dire pour tous $x\in V\cap S^{n-1}\backslash N$ il existe $i\leq m$ tel que $|x-x_i|<\theta$, donc $N$ est un $\theta$-net et les $\big\{B_V(x_i,\theta/2)\big\}_{i=1,...,m}$ sont donc disjoints deux à deux et toutes contenues dans $B_V(0,1+\frac{\theta}{2})$ d'ou : 
	\begin{equation*}
	m \text{Vol}(B_V(x_1,\frac{\theta}{2}))= \sum_{i=1}^{m}\text{Vol}(B_V(x_i,\frac{\theta}{2}))= \text{Vol}(\cup_{1\leq i \leq m} B_V(x_i,\frac{\theta}{2}))\leq \text{Vol}(B_V(0,1+\frac{\theta}{2}))
	\end{equation*}
	\begin{equation*}
	m\leq \frac{\text{Vol}(B_V(0,1+\frac{\theta}{2}))}{\text{Vol}(B_V(x_1,\frac{\theta}{2}))} 
	\end{equation*}
	Par homogénéité de la mesure de Lebesgue :
	\begin{equation*}
	m\leq\Bigg(\frac{1+\frac{\theta}{2}}{\frac{\theta}{2}}\Bigg)^k=  \Bigg(1+\frac{2}{\theta}\Bigg)^k<\big(\frac{3}{\theta}\big)^k
	\end{equation*}
\end{proof}

\subsection{Démonstration du théorème de Dvoretzky}
La demonstration du théorème de Dvoretzky repose sur le \cref{mtool} et la \cref{esE} qui sont démontrer dans cette partie. Dans un premier temps nous donnons un résultat de V.Milman qui est en grande partie la preuve du théorème de Dvoretzky.

\boxXx{
	\begin{theoreme}\label{mtool}
		Pour tous $\varepsilon>0$ il existe $c(\varepsilon)>0$ tel que pour tout $n\in \mathbb{N}^{*}$ et pour toute norme $||.||$ sur $\;\mathbb{R}^n$, $\ell_2^k$ s'injecte $(1+\varepsilon)$-continûment dans $(\mathbb{R}^n,||.||)$, pour un $k\geq c(\varepsilon).\big(\frac{M}{b}\big)^2n$.\\
		Où  $M=\int_{S^{n-1}}||x||d\mu(x)$ et $b>0$ le plus petit réel tel que $||.||\leq b |.|$
	\end{theoreme}
}
\begin{proof}
	Soit $\varepsilon>0$ et $1>\theta(\varepsilon)=:\theta>0$ donné par le \cref{lsB} nous allons montrer que $c(\theta(\varepsilon)) =: \frac{\theta^2}{8\log(\frac{3}{\theta})} $ convient, pour alléger les notations on note 
	\begin{enumerate}
		\item[-] $\eta =: \frac{\theta M}{b}$
		\item[-] $\kappa(\theta)=:c(\theta)\big(\frac{M}{b}\big)^2n$
	\end{enumerate}
	Évacuons un cas trivial, si $\kappa(\theta)<1$ alors $k=1$ convient car toute $1$-section est euclidienne, pour la suite on suppose donc $\kappa(\theta)\geq 1 \iff \frac{\eta^2n}{8}\geq \log(\frac{3}{\theta})$.\\
	Fixons un $k$ entier tel que $\kappa(\theta)\leq k < 2\kappa(\theta)$ possible car $\kappa(\theta)\geq 1$ et on se donne $A$ un $\theta$-net sur $\text{Vect}(e_1,...,e_k)\cap S^{n-1}$, avec $|A|\leq(\frac{3}{\theta})^k$. On alors :
	\begin{align*}
	\nu\Big(\bigcap_{x\in A}\big\{T\in O(n)\; ; \;  \big| ||Tx||-M \big|\leq b\eta\big\}\Big)& = 1-\nu\big(\bigcup_{x\in A}\big\{T\in O(n)\; ; \; \big| ||Tx||-M \big|>b\eta\big\}\big)& \\
	& \geq 1-|A|\nu\big(T\in O(n)\; ; \; \big| ||Ty||-M \big|>b\eta\big)& \text{pour un $y\in A$}\\
	& \geq 1 - |A|\mu\Big(y\in S^{n-1}\; ;\; \big| ||y||-M \big|>b\eta\Big) & \text{par le \cref{lhso}}
	\end{align*} 
	En appliquant la concentration de la mesure
	\begin{align*}
	\nu\Big(\bigcap_{x\in A}\big\{T\in O(n)\; ; \;  \big| ||Tx||-M \big|\leq b\eta\big\}\Big)&\geq 1 - |A|2e^{-\frac{\eta^2n}{2}}\\
	& > 1 - 2 \big(\frac{3}{\theta}\big)^k e^{-\frac{\eta^2n}{2}}\\
	& > 1 - 2 \exp\big(2\kappa(\theta)\log(\frac{3}{\theta})-\frac{\eta^2n}{2}\big)\\
	& > 1 -  2 e^{-\frac{\eta^2n}{4}}\\
	&> 1 - \frac{2}{3^2}\theta^2 >0 \hspace{16mm}\text{car $\frac{\eta^2n}{4}\geq 2\log(\frac{3}{\theta})$}
	\end{align*}	
	Donc il existe $T\in O(n)$ tel que pour tous $x\in A$ on ait $\big|||Tx||-M \big|\leq b \eta$, c'est à dire 
	\begin{equation*}
	M(1-\theta)=M-b\eta\leq ||Tx||\leq M+b\eta=M(1+\theta)
	\end{equation*}
	Par le \cref{lsB} pour tous $x\in \text{Vect}(e_1,...,e_k)$
	\begin{equation*}
	\frac{1}{\sqrt{1+\varepsilon}}|x| M\leq ||Tx||\leq \sqrt{1+\varepsilon}|x| M
	\end{equation*}
	et pour $\varepsilon<9^{-1}$ on peut prendre $\theta(\varepsilon)=\frac{\varepsilon}{9}$ et donc $c(\varepsilon)=c_0\frac{\varepsilon^2}{\log(\frac{c_1}{\varepsilon})} $ pour $c_0,c_1>0$.\\ 
\end{proof}
Il ne nous reste plus qu'as donner une borne inférieur à $\frac{M}{b}$, pour cela nous allons utiliser la \cref{rem0}, et le lemme suivant :
\newline\boxXx{
	\begin{lemme}[Dvoretzky-Rogers]
		Soit $||.||$ une norme sur $\mathbb{R}^n$ tel que $B_2^n$ est l'ellipsoïde de John de $B_{||.||}$, alors il existe une base orthonormée $\{x_i\}_{i=1,...,n}$ tel que $\forall 1\leq i\leq n$
		\begin{equation*}
		e^{-1}\big(1-\frac{i-1}{n}\big)\leq ||x_i||\leq 1 
		\end{equation*}
	\end{lemme}
}
\begin{proof}
	$S^{n-1}$ est compact et $||.||$ continue, on peux donc prendre un $x_1\in S^{n-1}$ qui maximise $||.||$ c'est à dire $||x_1||=1$, supposons que l'on ai $x_1,...,x_{k-1}$ avec $k\leq n$ tel que pour tous $1\leq i\leq k-1$ , $x_i$ maximise $||.||$ sur $S^{n-1}\backslash \text{Vect}(x_1,...,x_{k-1})\neq \emptyset$ car les $\{x_i\}_{i=1,...,k-1}$ sont orthogonaux deux à deux. On peut donc répéter le procéder pour trouver $x_{k}$ qui maximise $S^{n-1}\backslash \text{Vect}(x_1,...,x_{k-1})$, par récurrence on peut donc avoir $n$ vecteurs avec ses propriétés. Fixons $1\leq k \leq n$, $a,b\in\mathbb{R}^{*}$ et définissons :
	\begin{equation*}
	\mathcal{E} = \Big\{\sum_{i=1}^{n}a_ix_i\; ; \; \sum_{i=1}^{k-1}\big(\frac{a_i}{a}\big)^2+ \sum_{i=k}^{n}\big(\frac{b_i}{b}\big)^2\leq 1 \Big\}
	\end{equation*}
	Supposons $\sum_{i=1}^{n}a_ix_i\in \mathcal{E}$, alors $\sum_{i=1}^{k-1}a_ix_i\in aB_2^n$ et donc $||\sum_{i=1}^{k-1}a_ix_i||\leq a$.
	Si $x\in \text{Vect}(x_k,...,x_n)\cap B^n_2$ on a $||x||\leq ||x_k||$ par construction, et donc $\sum_{i=k}^{n}a_ix_i\in bB_2^n \; \Rightarrow \; ||\sum_{i=k}^{n}a_ix_i ||\leq b||x_k||$ , ce qui nous donne la majoration suivante 
	\begin{equation*}
	||\sum_{i=1}^{n}a_ix_i||\leq ||\sum_{i=1}^{k-1}a_ix_i||+||\sum_{i=k}^{n}a_ix_i||\leq a + b||x_k||
	\end{equation*}
	Posons $\phi\in GL(n)$ définit par $\phi(\sum_{i=1}^{n}a_ix_i)=\sum_{i=1}^{k-1}aa_ix_i+\sum_{i=k}^{n}ba_ix_i$ on a $\phi = \text{diag}\big(\overbrace{a,...,a}^{(k-1)\times},\overbrace{b,...,b}^{(n-k+1) \times}\big)$ et donc $\det \phi = a^{k-1}b^{n-k+1}$ d'où :
	\begin{equation*}
	\int_{\mathcal{E}} dx_1...dx_n = \int_{B_2^n} \det \phi dx_1...dx_n= a^{k-1}b^{n-k-1}\int_{B_2^n}dx_1...dx_n
	\end{equation*}
	On prend $a+b||x_k||= 1$ de sorte que $\mathcal{E}\subset K$, comme $B_2^n$ est l'ellipsoïde de volume maximale inclue dans $K$, on a que  
	\begin{equation*}
	1\geq\frac{\int_{\mathcal{E}} dx_1...dx_n}{\int_{B_2^n}dx_1...dx_n}=a^{k-1}b^{n-k+1}
	\end{equation*}
	Fixons donc pour $k\geq 2$ , $b=\frac{1-a}{||x_k||}$ et $a=\frac{k-1}{n}$, en remplaçant dans l'inégalité on obtient :
	\begin{equation*}
	1\geq a^{k-1} \Big(\frac{1-a}{||x_k||}\Big)^{n-k+1} \; \iff \; ||x_k||\geq a^{\frac{k-1}{n-k+1}}(1-a) = \Big(\frac{k-1}{n}\Big)^{\frac{k-1}{n-k+1}}\Big(1-\frac{k-1}{n}\Big)
	\end{equation*}
	et $\log a^{\frac{k-1}{n-k+1}}= \frac{k-1}{n-k+1}\log\Big(\frac{k-1}{n}\Big)>-1$.
	
\end{proof}

\boxXx{
	\begin{proposition}\label{esE}
		Soit $||.||$ une norme sur $\mathbb{R}^n$ tel que $B_2^n$ est l'ellipsoïde de John de $B_{||.||}$, alors il existe $c>0$ tel que 
		\begin{equation*}
			M=:\int_{S^{n-1}} ||x||d\mu(x) \geq c \sqrt{\frac{\log n}{n}}
		\end{equation*}
	\end{proposition}
}
\begin{proof}
	Par le lemme de Dvoretzky-Rogers il existe une base orthonormé $x_1,...,x_n$ tel que pour $1\leq i \leq \tilde{n}=:\big\lceil\frac{n}{2}\big\rceil$ la partie entière supérieure de $\frac{n}{2}$, $||x_i||\geq e^{-1}\Big(1-\frac{\tilde{n} -1}{n}\Big)\geq e^{-1}\Big(1-\frac{\frac{n}{2}+1 -1}{n}\Big)= (2e)^{-1}$. Comme $\mu$ est invariante par composition par une transformation orthogonale on a que  
	\begin{equation*}
	M=:\int_{S^{n-1}} ||\sum_{i=1}^{n}a_ix_i||d\mu(a)= \int_{S^{n-1}} ||\sum_{i=1}^{n-1}a_ix_i-a_nx_n||d\mu(a)
	\end{equation*}
	et donc 
	\begin{align*}
	M&=\frac{1}{2}\int_{S^{n-1}} ||\sum_{i=1}^{n}a_ix_i||d\mu(a)+ \frac{1}{2}\int_{S^{n-1}} ||\sum_{i=1}^{n-1}a_ix_i-a_nx_n||d\mu(a)\\
	&\geq\frac{1}{2}\int_{S^{n-1}} 2\max\Big\{||\sum_{i=1}^{n-1}a_ix_i||,||a_nx_n||\Big\}d\mu(a)\geq ...\geq \int_{S^{n-1}} \max_{1\leq i \leq \tilde{n}}\Big\{|a_i|\;||x_i||\Big\}d\mu(a)\\
	&\geq \int_{S^{n-1}} \max_{1\leq i \leq \tilde{n}}\Big\{|a_i|\;||x_i||\Big\}d\mu(a) \geq (2e)^{-1}\int_{S^{n-1}} \max_{1\leq i \leq \tilde{n}}|a_i| d\mu(a)	
	\end{align*}
	Soit $(g_1,...,g_n)$ , des variables aléatoire i.i.d de loi $\mathcal{N}(0,1)$ alors 
	\begin{equation*}
	\int_{S^{n-1}} \max_{1\leq i \leq \tilde{n}}|a_i| d\mu(a) =\mathbb{E}\Big[\big(\sum_{i=1}^{n}g_i^2\big)^{-\frac{1}{2}} \max_{1\leq i \leq \tilde{n}}|g_i|\Big]
	\end{equation*}
	
	\noindent Par le \cref{gaussind} $\big(\sum_{i=1}^{n}g_i^2\big)^{-\frac{1}{2}}(g_1,...,g_n)$ et $(\sum_{i=1}^{n}g_i^2\big)^{\frac{1}{2}}$ sont des variables aléatoires indépendantes, on a donc 
	\begin{equation*}
	\mathbb{E}\Big[\big(\sum_{i=1}^{n}g_i^2\big)^{-\frac{1}{2}} \max_{1\leq i \leq \tilde{n}}|g_i|\Big] . \mathbb{E}\Big[\big(\sum_{i=1}^{n}g_i^2\big)^{\frac{1}{2}}\Big] = \mathbb{E}\big[\max_{1\leq i \leq \tilde{n}}|g_i|\big]
	\end{equation*}
	la fonction racine carré est concave, par l'inégalité de Jensen on a donc :
	\begin{equation*}
	\mathbb{E}\big[\big(\sum_{i=1}^{n}g_i^2\big)^{\frac{1}{2}}\big]\leq \mathbb{E}\big[\sum_{i=1}^{n}g_i^2\big]^{\frac{1}{2}}= \sqrt{n} \mathbb{E}[g_1^2]^{\frac{1}{2}}=\sqrt{n} 
	\end{equation*}
	
	\noindent Et finalement par le \cref{ming}, il existe $K>0$ tel que :
	\begin{equation*}
	M\geq \frac{1}{2e\sqrt{n}} \mathbb{E}\big[\max_{1\leq i \leq \tilde{n}}|g_i|\big]\geq \frac{K}{2e}\sqrt{\frac{\log n}{n}}
	\end{equation*}
\end{proof}
\begin{leftbar}
\noindent On peut donc réunir la \cref{esE} et le \cref{mtool} pour obtenir $k \geq c(\varepsilon)\log n$ lorsque $B_2^n$ est l'ellipsoïde de John pour $B_{||.||}$, en utilisant la \cref{rem0} quitte à diviser $k$ par $2$, on peut généralisé à toutes les normes et donc conclure la démonstration du théorème de Dvoretzky.
\end{leftbar}
\section{Sections presque euclidiennes de $\ell_p^n$}
\subsection{cas $1\leq p <2$}
\boxXx{
\begin{proposition}\label{l10}
	Soit $1\leq p < 2$, pour tout $\varepsilon>0$ il existe $c(\varepsilon)>0$ tel que pour tous $n\geq 2$, $\ell_2^k$ s'injecte $(1+\varepsilon)$-continûment dans $\ell^n_p$ pour un $k\geq c(\varepsilon)n$.
\end{proposition}
}
\begin{proof}
	Par l'inégalité de Hölder $||x||_p \leq n^{\frac{1}{p}-\frac{1}{2}}|x|$, c'est-à-dire $b\leq n^{\frac{1}{p}-\frac{1}{2}}$. Comme les normes sont des applications convexes, par l'inégalité de Jensen :
	\begin{equation*}
	\mathbb{E}\Big[\big(\sum_{i=1}^{n}|x_i|^p\big)^{\frac{1}{p}}\Big]\geq \big(\sum_{i=1}^{n}\mathbb{E}[|x_i|]^p\big)^{\frac{1}{p}}=n^{\frac{1}{p}}\sqrt{\frac{\pi}{2}}
	\end{equation*}
	Et donc 
	\begin{align*}
		M&=:\int_{S^{n-1}}||x||_p d\mu(x)\\
		&=\mathbb{E}\Bigg[\frac{||x||_p}{|x|}\Bigg]\\
		&=\frac{\mathbb{E}\big[||x||_p\big]}{\mathbb{E}\big[|x|\big]}\geq n^{\frac{1}{p}-\frac{1}{2}}\sqrt{\frac{\pi}{2}}\\
	\end{align*}
	Par le \cref{mtool} $\;\ell^k_2$ s'injecte $(1+\varepsilon)$-continûment dans $\ell^n_p$ pour un $k\geq c(\varepsilon)(\frac{E}{b})^2n=\tilde{c}(\varepsilon)n$. 
\end{proof}
\subsection{cas $2 \leq p < \infty$}
On pourrais utiliser la même inégalité que dans la \cref{l10}, cela nous donnerais une estimation de l'ordre de $k\geq c(\varepsilon)n^{\frac{2}{p}}$ (car ici $b\leq 1$), mais il se trouve que l'on peut donner de meilleur estimation en séparant les cas en deux, lorsque $k$ est petit devant $n$ on a la proposition suivante :
\newline\boxXx{\begin{proposition}
		Pour tout $\varepsilon>0$ et $2\leq p$,  il existe $c_p(\varepsilon)>0$ tel que pour tout $n\in \mathbb{N}$ avec $p<\log n$, $\ell_2^k$ s'injecte $(1+\varepsilon)$-continûment dans $\ell_p^n$, pour $k\geq c_p(\varepsilon)n^{\frac{2}{p}}$.
\end{proposition}}
\begin{proof}
\begin{equation*}
	M =: \int_{S^{n-1}}||x||^p d\mu(x) = \mathbb{E}\Bigg[\frac{\big(\sum_{i=1}^{n}|x_i|^p\big)^{\frac{1}{p}}}{\big(\sum_{i=1}^{n}|x_i|^2\big)^{\frac{1}{2}}}\Bigg]= \frac{\mathbb{E}\Bigg[\big(\sum_{i=1}^{n}|x_i|^p\big)^{\frac{1}{p}}\Bigg]}{\mathbb{E}\Bigg[\big(\sum_{i=1}^{n}|x_i|^2\big)^{\frac{1}{2}}\Bigg]}
\end{equation*}
Par l'inégalité de Hölder on a $||x||_p\leq |x|$, donc $b\leq1$. Posons $m=:\lfloor e^p\rfloor$ et divisons $\{1,...,n\}$ en $N=\lceil\frac{n}{m}\rceil$ parties disjointes $I_1,...,I_N$ tel que pour $j<N$, $\text{card}(I_j)=m$, on a 
	\begin{align*}
		\mathbb{E}\Big[\Big(\sum_{i=1}^{n}|g_i|^p\Big)^{\frac{1}{p}}\Big]&= \mathbb{E}\Big[\Big(\sum_{j\leq N}\sum_{i\in I_j}|g_i|^p\Big)^{\frac{1}{p}}\Big]\\
		&\geq\mathbb{E}\Big[\Big(\sum_{j\leq N}(\underset{i\in I_j}{\max|g_i|})^p\Big)^{\frac{1}{p}}\Big]\\
		&\geq \Big(\sum_{j\leq N}\big(\underset{i\in I_j}{\mathbb{E}[\max|g_i|]}\big)^p\Big)^{\frac{1}{p}}\\
		&\geq(N-1)^{\frac{1}{p}}c\sqrt{\log m} \hspace{2mm} \text{par le \cref{ming}}
	\end{align*}
	Où $c>0$ est une constante universelle, de plus :
	\begin{align*}
	\frac{(N-1)^{\frac{1}{p}}}{N^{\frac{1}{p}}}&=\big(\frac{N-1}{N}\big)^{\frac{1}{p}}\\
	&= \big(1-\frac{1}{N}\big)^{\frac{1}{p}}\\
	&\geq \big(1-\frac{1}{2}\big)^{\frac{1}{p}}=2^{-\frac{1}{p}}
	\end{align*}
	\noindent Car $N\geq 2$ par hypothèse, et finalement :
	\begin{align*}
		M &\geq N^{\frac{1}{p}}2^{-\frac{1}{p}} c\sqrt{\log \lfloor e^p\rfloor} n^{-\frac{1}{2}}\\
		& \geq n^{\frac{1}{p}-\frac{1}{2}}C_p
	\end{align*}
	Où $C_p =2^{-\frac{1}{p}} c\sqrt{\log \lfloor e^p\rfloor}\underset{p\to\infty}{\sim} c\sqrt{p}$.\\
	Par le \cref{mtool} $\ell_2^k$ s'injecte $(1+\varepsilon)$-continûment dans $\ell_p^n$, pour
	\begin{align*}
		k &\geq c(\varepsilon)\big(\frac{E}{b}\big)^2n\\
		&\geq c_p(\varepsilon)n^{\frac{2}{p}}, \hspace{3mm} \text{avec $c_p(\varepsilon) = c(\varepsilon)C_p^2\underset{p\to\infty}{\sim} \tilde{c}(\varepsilon)p$}
	\end{align*}
\end{proof}
\begin{rem}
	Dans le cas contraire si $p\geq \log n$, alors $n^{\frac{2}{p}}\leq e^2$ donc dans ce cas la meilleur estimation est celle donné par le théorème de Dvoretzky.
\end{rem}
\newpage
\nocite{GP}
\nocite{VM2}
\nocite{VMGS}
\printbibliography


\end{document}


